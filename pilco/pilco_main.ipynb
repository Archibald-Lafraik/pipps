{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import random\n",
    "import gym\n",
    "import jax.random as jrandom\n",
    "from jax import vmap, jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "from constants import SEED\n",
    "from policy import policy_grad, lr_gradients, get_sequence_rewards\n",
    "from pilco_utils import get_trajectories, rollout_episode\n",
    "from rff import phi_X, phi_X_batch\n",
    "from trans_model import prior, train_transition_models, predict, lklhood_grad, marg_lklhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:145: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  \"Agent's minimum observation space value is -infinity. This is probably too low.\"\n",
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:149: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  \"Agent's maxmimum observation space value is infinity. This is probably too high\"\n",
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:201: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('InvertedPendulum-v4')\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run random policy to collect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "INIT_EPISODES = 500\n",
    "BUFFER_CAPACITY = 1000\n",
    "HORIZON = 15\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity=BUFFER_CAPACITY)\n",
    "\n",
    "for ep in range(INIT_EPISODES):\n",
    "    cur_state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    for t in range(HORIZON):\n",
    "        action = np.array([random.uniform(-1., 1.)])\n",
    "        prev_state = cur_state\n",
    "\n",
    "        cur_state, _, done, _ = env.step(action)\n",
    "        replay_buffer.push(prev_state, action.squeeze(), cur_state)\n",
    "\n",
    "\n",
    "print(len(replay_buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute posterior distribution for transition models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = jnp.full((state_dim + 1,), .9)\n",
    "# BETAS = jnp.full((4,), 20.)\n",
    "BETAS = jnp.load('optimal_beta.npy')\n",
    "ALPHA = .3\n",
    "N = 1000\n",
    "NUM_FEATURES = 1000 \n",
    "# lengthscales = jnp.asarray(np.load('optimal_lengthscales.npy'))\n",
    "lengthscales = jnp.full((4, NUM_FEATURES, 1), .6) \n",
    "# coefs = jnp.full_like(lengthscales, 0.3)\n",
    "coefs = jnp.load('optimal_coefs.npy')\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models_pre = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "trans_models_post = train_transition_models(\n",
    "    replay_buffer, BETAS, trans_models_pre, NUM_FEATURES, lengthscales, coefs, SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise Transition Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, objective: 371.58062744140625\n",
      "Step 5, objective: 369.9600830078125\n",
      "Step 10, objective: 368.3751525878906\n",
      "Step 15, objective: 366.8271484375\n",
      "Step 20, objective: 365.3169250488281\n",
      "Step 25, objective: 363.8446960449219\n",
      "Step 30, objective: 362.410400390625\n",
      "Step 35, objective: 361.01336669921875\n",
      "Step 40, objective: 359.6528625488281\n"
     ]
    }
   ],
   "source": [
    "key = SEED\n",
    "cur_keys = jrandom.split(key, num=3)\n",
    "N = 1000\n",
    "SEQ_LEN = 20\n",
    "MODEL_NOISE = 0.1\n",
    "\n",
    "transitions = replay_buffer.memory[:SEQ_LEN]\n",
    "states = jnp.array(list(map(lambda t: t.state, transitions)))\n",
    "actions = jnp.array(list(map(lambda t: t.action, transitions)))\n",
    "next_states = jnp.array(list(map(lambda t: t.next_state, transitions)))\n",
    "\n",
    "params = jnp.array([BETAS])\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=0.05),\n",
    "    # optax.scale(-1.0)\n",
    ")\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for i in range(100):\n",
    "    trans = jrandom.normal(cur_keys[0], shape=(N, SEQ_LEN, 4))\n",
    "    omega = jrandom.normal(cur_keys[1], shape=(N, NUM_FEATURES, 2))\n",
    "    phi = jrandom.uniform(cur_keys[2], minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES, 1))\n",
    "\n",
    "    grads = lklhood_grad(states, NUM_FEATURES, lengthscales, coefs, params[0], MODEL_NOISE, 4, actions, next_states, trans, omega, phi, *trans_models_post)\n",
    "\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        objective = marg_lklhood(states, NUM_FEATURES, lengthscales, coefs, params[0], MODEL_NOISE, actions, next_states, trans, omega, phi, *trans_models_post)\n",
    "        print(f\"Step {i}, objective: {objective}\")\n",
    "\n",
    "np.save('optimal_beta.npy', np.asarray(params[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Next State Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthscales = jnp.asarray(np.load('optimal_lengthscales.npy'))\n",
    "\n",
    "start_state = env.reset()\n",
    "action = jnp.array([.5])\n",
    "N = 1000\n",
    "\n",
    "@jit\n",
    "def pred(start_st, trans_eps, state_eps, omega, phi, m_d1, m_d2, m_d3, m_d4):\n",
    "    model_input = jnp.stack([start_st, jnp.full((4,), action)]).T\n",
    "    input = phi_X_batch(model_input, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "\n",
    "    means = jnp.concatenate([m_d1[0], m_d2[0], m_d3[0], m_d4[0]])\n",
    "    covs = jnp.zeros((means.shape[0], means.shape[0]))\n",
    "    covs = covs.at[:NUM_FEATURES, :NUM_FEATURES].set(m_d1[1])\n",
    "    covs = covs.at[NUM_FEATURES:NUM_FEATURES * 2, NUM_FEATURES:NUM_FEATURES * 2].set(m_d2[1])\n",
    "    covs = covs.at[NUM_FEATURES * 2:NUM_FEATURES * 3, NUM_FEATURES * 2:NUM_FEATURES * 3].set(m_d3[1])\n",
    "    covs = covs.at[NUM_FEATURES * 3:NUM_FEATURES * 4, NUM_FEATURES * 3:NUM_FEATURES * 4].set(m_d4[1])\n",
    "    d1, d2, d3, d4 = predict(means, covs, BETA, input.reshape(-1), trans_eps)\n",
    "\n",
    "    next_mean = jnp.array([d1, d2, d3, d4]) + start_st\n",
    "    next_state = next_mean + state_eps * 0.3\n",
    "    return next_state\n",
    "\n",
    "foo = vmap(pred, (None, 0, 0, 0, 0, None, None, None, None))\n",
    "\n",
    "keys = jrandom.split(SEED, num=4)\n",
    "state = jrandom.normal(keys[0], shape=(N, 4))\n",
    "trans = jrandom.normal(keys[1], shape=(N, 4))\n",
    "omega = jrandom.normal(keys[2], shape=(N, NUM_FEATURES, 2))\n",
    "phi = jrandom.uniform(keys[3], minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES,))\n",
    "\n",
    "\n",
    "predictions_post = foo(jnp.zeros((4,)), state, trans, omega, phi, *trans_models_post).mean(axis=0)\n",
    "print(f\"Pred: {predictions_post}\")\n",
    "print(f\"True: {env.step(action)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = replay_buffer.memory[:100]\n",
    "states = jnp.array(list(map(lambda t: t.state, transitions)))\n",
    "actions = jnp.array(list(map(lambda t: t.action, transitions)))\n",
    "next_states = jnp.array(list(map(lambda t: t.next_state, transitions)))\n",
    "\n",
    "key = SEED\n",
    "num_states = 100\n",
    "pred_next_states = np.zeros((num_states,))\n",
    "xs = np.linspace(-.3, .3, num_states)\n",
    "\n",
    "for i, start_state in enumerate(states):\n",
    "    key, subkey = jrandom.split(key)\n",
    "    keys = jrandom.split(subkey, num=4)\n",
    "\n",
    "    state_eps = jrandom.normal(keys[0], shape=(N, 4))\n",
    "    trans_eps = jrandom.normal(keys[1], shape=(N, 4))\n",
    "    omega = jrandom.normal(keys[2], shape=(N, NUM_FEATURES, 2))\n",
    "    phi = jrandom.uniform(keys[3], minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES,))\n",
    "\n",
    "    pred_st = foo(start_state, state_eps, trans_eps, omega, phi, *trans_models_post).mean(axis=0)[0]\n",
    "    pred_next_states[i] = pred_st\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Step {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "# plt.vlines(states[:, 0], -0.32, next_states[:, 0], color='orange', linestyle='dashed')\n",
    "plt.scatter(states[:, 0], next_states[:, 0], color='orange', label=\"True transitions\")\n",
    "# plt.vlines(states[:, 0], -0.32, pred_next_states, color='cornflowerblue', linestyle='dashed')\n",
    "plt.scatter(states[:, 0], pred_next_states, color='cornflowerblue', label=\"Predicted transitions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE = 0.1\n",
    "N = 10000\n",
    "eps = 0.0001\n",
    "\n",
    "costs = np.zeros((2,))\n",
    "key = SEED\n",
    "for j, i in enumerate([-1, 1]):\n",
    "    keys = jrandom.split(key, num=4)\n",
    "    state_epsilons = jrandom.normal(key=keys[0], shape=(N, HORIZON, 4))\n",
    "    trans_epsilons = jrandom.normal(key=keys[1], shape=(N, HORIZON, 4))\n",
    "    omegas = jrandom.normal(key=keys[2], shape=(N, HORIZON, NUM_FEATURES, 2))\n",
    "    phis = jrandom.uniform(key=keys[3], minval=0, maxval=2 * jnp.pi, shape=(N, HORIZON, NUM_FEATURES))\n",
    "\n",
    "    theta = jnp.array([1., 1., 1., 1., 1 + i * eps])\n",
    "    trajectories = get_trajectories(\n",
    "        theta, BETA, env, *trans_models_post, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons, trans_epsilons, omegas, phis\n",
    "        )\n",
    "    avg_cost = vmap(get_sequence_rewards, (0,))(trajectories).mean()\n",
    "    costs[j] = avg_cost\n",
    "    print(avg_cost)\n",
    "\n",
    "diff_grad = (costs[1] - costs[0]) / (2 * eps)\n",
    "print(diff_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: [-0.33891183 -0.05050422 -0.64287704  0.84783596  0.2908255 ]\n",
      "RP: [ 0.00662371 -0.00318408 -0.00130731 -0.02781972  0.01692043]\n"
     ]
    }
   ],
   "source": [
    "theta = jnp.full((state_dim + 1,), 1.)\n",
    "BETA = 1.\n",
    "ALPHA = 0.3\n",
    "N = 1000\n",
    "HORIZON = 10\n",
    "NUM_FEATURES = 1000\n",
    "NOISE = 0.2\n",
    "lengthscales = jnp.full((NUM_FEATURES,), .1)\n",
    "coefs = jnp.full_like(lengthscales, 0.06)\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "trans_models_post = train_transition_models(replay_buffer, BETA, trans_models, NUM_FEATURES, lengthscales, coefs, SEED)\n",
    "\n",
    "model_d1, model_d2, model_d3, model_d4 = trans_models_post\n",
    "\n",
    "keys = jrandom.split(SEED, num=7)\n",
    "state_epsilons = jrandom.normal(key=keys[0], shape=(N, HORIZON, 4))\n",
    "trans_epsilons = jrandom.normal(key=keys[1], shape=(N, HORIZON, 4))\n",
    "omegas = jrandom.normal(key=keys[2], shape=(N, NUM_FEATURES, 2))\n",
    "phis = jrandom.uniform(key=keys[3], minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES))\n",
    "extra_epsilons = jrandom.normal(key=keys[4], shape=(N, HORIZON, 4))\n",
    "extra_omegas = jrandom.normal(key=keys[5], shape=(N, NUM_FEATURES, 2))\n",
    "extra_phis = jrandom.uniform(key=keys[6], minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES,))\n",
    "\n",
    "# LR gradients\n",
    "trajectories = get_trajectories(\n",
    "    theta, BETA, env, *trans_models_post, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons, trans_epsilons, omegas, phis\n",
    "    )\n",
    "lr_grads = lr_gradients(\n",
    "    theta, BETA, *trans_models_post, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, trajectories, trans_epsilons, omegas, phis\n",
    "    )\n",
    "print(f\"LR: {lr_grads}\")\n",
    "\n",
    "# RP gradients\n",
    "rp_grads = policy_grad(\n",
    "    theta, BETA, *trans_models_post, env, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons, trans_epsilons, omegas, phis\n",
    ")\n",
    "print(f\"RP: {rp_grads}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle-based PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 50\n",
    "NOISE = 0.1\n",
    "HORIZON = 10\n",
    "TEST_HORIZON = 50\n",
    "N = 1000\n",
    "TRAIN_LOOPS = 5\n",
    "key = SEED\n",
    "\n",
    "trans_models = trans_models_post\n",
    "\n",
    "theta = jnp.full((state_dim + 1,), 0.)\n",
    "params = jnp.array([theta])\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=0.008),\n",
    "    # optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for ep in range(MAX_EPISODES):\n",
    "    subkeys = jrandom.split(key, num=6)\n",
    "    key = subkeys[0]\n",
    "\n",
    "    state_epsilons = jrandom.normal(key=subkeys[1], shape=(N, HORIZON, 4))\n",
    "    trans_epsilons = jrandom.normal(key=subkeys[2], shape=(N, HORIZON, 4))\n",
    "    omegas = jrandom.normal(key=subkeys[3], shape=(N, HORIZON, NUM_FEATURES, 2))\n",
    "    phis = jrandom.uniform(key=subkeys[4], minval=0, maxval=2 * jnp.pi, shape=(N, HORIZON, NUM_FEATURES))\n",
    "\n",
    "    # Train model with all available data\n",
    "    trans_models = train_transition_models(\n",
    "        replay_buffer, BETA, trans_models, NUM_FEATURES, lengthscales, coefs, subkeys[5]\n",
    "    )\n",
    "\n",
    "    for _ in range(TRAIN_LOOPS):\n",
    "        # Compute the policy gradient\n",
    "        # trajectories = get_trajectories(theta, BETA, env, *trans_models, HORIZON, NOISE, state_epsilons, trans_epsilons)\n",
    "        # grads = lr_gradients(theta, BETA, *trans_models, HORIZON, NOISE, trajectories, trans_epsilons)\n",
    "\n",
    "        # RP gradients\n",
    "        grads = policy_grad(\n",
    "            theta,\n",
    "            BETA,\n",
    "            *trans_models,\n",
    "            env,\n",
    "            HORIZON,\n",
    "            NUM_FEATURES,\n",
    "            lengthscales,\n",
    "            coefs,\n",
    "            NOISE,\n",
    "            state_epsilons,\n",
    "            trans_epsilons,\n",
    "            omegas,\n",
    "            phis\n",
    "        )\n",
    "\n",
    "        params = jnp.array([theta])\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        theta = params[0]\n",
    "\n",
    "    # Roll-out policy online for an episode and add to replay buffer\n",
    "    cur_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, theta)\n",
    "\n",
    "    if ep % 1 == 0:\n",
    "        print(f\"Ep {ep}, objective: {cur_obj}, theta: {theta}\")\n",
    "\n",
    "\n",
    "final_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, theta)\n",
    "print(f\"Final score: {final_obj}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect and organise training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = replay_buffer.get_train_test_arrays()\n",
    "\n",
    "train_X_d1 = train_X[:, :2]\n",
    "train_X_d2 = train_X[:, 2:4]\n",
    "train_X_d3 = train_X[:, 4:6]\n",
    "train_X_d4 = train_X[:, 6:8]\n",
    "test_X_d1 = test_X[:, :2]\n",
    "test_X_d2 = test_X[:, 2:4]\n",
    "test_X_d3 = test_X[:, 4:6]\n",
    "test_X_d4 = test_X[:, 6:8]\n",
    "\n",
    "train_y_d1 = train_y[:, 0]\n",
    "train_y_d2 = train_y[:, 1]\n",
    "train_y_d3 = train_y[:, 2]\n",
    "train_y_d4 = train_y[:, 3]\n",
    "test_y_d1 = test_y[:, 0]\n",
    "test_y_d2 = test_y[:, 1]\n",
    "test_y_d3 = test_y[:, 2]\n",
    "test_y_d4 = test_y[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2000\n",
    "\n",
    "omega = jrandom.normal(key=SEED, shape=(NUM_FEATURES, 2))\n",
    "phi = jrandom.uniform(key=SEED, minval=0, maxval=2 * jnp.pi, shape=(NUM_FEATURES, 1))\n",
    "lengthscales = jnp.full((NUM_FEATURES, 1), 1.)\n",
    "coefs = jnp.full_like(lengthscales, 1.)\n",
    "\n",
    "phi_X_train_d1 = phi_X(train_X_d1, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d1 = phi_X(test_X_d1, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d2 = phi_X(train_X_d2, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d2 = phi_X(test_X_d2, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d3 = phi_X(train_X_d3, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d3 = phi_X(test_X_d3, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d4 = phi_X(train_X_d4, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d4 = phi_X(test_X_d4, NUM_FEATURES, lengthscales, coefs, omega, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RFF transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_d1 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d2 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d3 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d4 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "\n",
    "model_d1.posterior(phi_X_train_d1, train_y_d1)\n",
    "model_d2.posterior(phi_X_train_d2, train_y_d2)\n",
    "model_d3.posterior(phi_X_train_d3, train_y_d3)\n",
    "model_d4.posterior(phi_X_train_d4, train_y_d4)\n",
    "\n",
    "d1_preds = np.zeros_like(test_y_d1)\n",
    "d2_preds = np.zeros_like(test_y_d2)\n",
    "d3_preds = np.zeros_like(test_y_d3)\n",
    "d4_preds = np.zeros_like(test_y_d4)\n",
    "\n",
    "for i in range(test_y_d1.shape[0]):\n",
    "    d1_preds = model_d1.predict(phi_X_test_d1).mean()\n",
    "    d2_preds = model_d2.predict(phi_X_test_d2).mean()\n",
    "    d3_preds = model_d3.predict(phi_X_test_d3).mean()\n",
    "    d4_preds = model_d4.predict(phi_X_test_d4).mean()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE d1: {metrics.mean_absolute_error(test_y_d1, d1_preds)}\")\n",
    "print(f\"MSE d2: {metrics.mean_absolute_error(test_y_d2, d2_preds)}\")\n",
    "print(f\"MSE d3: {metrics.mean_absolute_error(test_y_d3, d3_preds)}\")\n",
    "print(f\"MSE d4: {metrics.mean_absolute_error(test_y_d4, d4_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Gaussian process transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gp_d1 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d2 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d3 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d4 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "\n",
    "gp_d1.fit(train_X_d1, train_y_d1)\n",
    "gp_d2.fit(train_X_d2, train_y_d2)\n",
    "gp_d3.fit(train_X_d3, train_y_d3)\n",
    "gp_d4.fit(train_X_d4, train_y_d4)\n",
    "\n",
    "d1_preds_gp = np.zeros_like(test_y_d1)\n",
    "d2_preds_gp = np.zeros_like(test_y_d2)\n",
    "d3_preds_gp = np.zeros_like(test_y_d3)\n",
    "d4_preds_gp = np.zeros_like(test_y_d4)\n",
    "\n",
    "d1_std_gp = np.zeros_like(test_y_d1)\n",
    "d2_std_gp = np.zeros_like(test_y_d2)\n",
    "d3_std_gp = np.zeros_like(test_y_d3)\n",
    "d4_std_gp = np.zeros_like(test_y_d4)\n",
    "\n",
    "for i in range(test_y_d1.shape[0]):\n",
    "    d1_preds_gp, d1_std_gp = gp_d1.predict(test_X_d1, return_std=True)\n",
    "    d2_preds_gp, d2_std_gp = gp_d2.predict(test_X_d2, return_std=True)\n",
    "    d3_preds_gp, d3_std_gp = gp_d3.predict(test_X_d3, return_std=True)\n",
    "    d4_preds_gp, d4_std_gp = gp_d4.predict(test_X_d4, return_std=True)\n",
    "\n",
    "print(f\"MSE d1: {metrics.mean_absolute_error(test_y_d1, d1_preds_gp)}, kernel: {gp_d1.kernel_}\")\n",
    "print(f\"MSE d2: {metrics.mean_absolute_error(test_y_d2, d2_preds_gp)}, kernel: {gp_d2.kernel_}\")\n",
    "print(f\"MSE d3: {metrics.mean_absolute_error(test_y_d3, d3_preds_gp)}, kernel: {gp_d3.kernel_}\")\n",
    "print(f\"MSE d4: {metrics.mean_absolute_error(test_y_d4, d4_preds_gp)}, kernel: {gp_d4.kernel_}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d0f0160cacfb35fe8642b675725525dd1061e27bd6ae6db2781150554066f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
