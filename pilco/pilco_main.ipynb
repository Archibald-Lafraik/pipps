{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import random\n",
    "import gym\n",
    "import jax.random as jrandom\n",
    "from jax import vmap, jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "from constants import SEED\n",
    "from policy import policy_grad, lr_gradients, trajectory_value\n",
    "from pilco_utils import get_trajectories, rollout_episode\n",
    "from rff import phi_X, phi_X_batch\n",
    "from trans_model import prior, train_transition_models, predict, predict_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:145: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  \"Agent's minimum observation space value is -infinity. This is probably too low.\"\n",
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:149: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  \"Agent's maxmimum observation space value is infinity. This is probably too high\"\n",
      "/Users/damso/Year4/FYP/pipps/venv/lib/python3.7/site-packages/gym/utils/env_checker.py:201: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('InvertedPendulum-v4')\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run random policy to collect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "INIT_EPISODES = 1000\n",
    "BUFFER_CAPACITY = 1000\n",
    "HORIZON = 20\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity=BUFFER_CAPACITY)\n",
    "\n",
    "for ep in range(INIT_EPISODES):\n",
    "    cur_state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    for t in range(HORIZON):\n",
    "        action = np.array([random.uniform(-1., 1.)])\n",
    "        prev_state = cur_state\n",
    "\n",
    "        cur_state, _, done, _ = env.step(action)\n",
    "        replay_buffer.push(prev_state, action.squeeze(), cur_state)\n",
    "\n",
    "\n",
    "print(len(replay_buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute posterior distribution for transition models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = jnp.full((state_dim + 1,), .9)\n",
    "BETA = .1\n",
    "ALPHA = .3\n",
    "N = 1000\n",
    "NUM_FEATURES = 1000 \n",
    "lengthscales = jnp.full((NUM_FEATURES,), .1)\n",
    "coefs = jnp.full_like(lengthscales, 0.000001)\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "trans_models = train_transition_models(\n",
    "    replay_buffer, BETA, trans_models, NUM_FEATURES, lengthscales, coefs, SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Next State Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = env.reset()\n",
    "action = jnp.array([.1])\n",
    "N = 1000\n",
    "\n",
    "model_d1, model_d2, model_d3, model_d4 = trans_models\n",
    "\n",
    "@jit\n",
    "def pred(trans_eps, state_eps, omega, phi):\n",
    "    model_input = jnp.stack([start_state, jnp.full((4,), action)]).T\n",
    "    input = phi_X_batch(model_input, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "\n",
    "    means = jnp.concatenate([model_d1[0], model_d2[0], model_d3[0], model_d4[0]])\n",
    "    covs = jnp.diag(jnp.concatenate([\n",
    "        jnp.diag(model_d1[1]), jnp.diag(model_d2[1]), jnp.diag(model_d3[1]), jnp.diag(model_d4[1])\n",
    "    ]))\n",
    "    d1, d2, d3, d4 = predict(means, covs, BETA, input.reshape(-1), trans_eps)\n",
    "\n",
    "    next_mean = jnp.array([d1, d2, d3, d4]) + start_state\n",
    "    next_state = next_mean + state_eps * 0.1\n",
    "    return next_state\n",
    "\n",
    "foo = vmap(vmap(pred, (None, 0, None, None)), (0, None, 0, 0))\n",
    "\n",
    "trans = jrandom.normal(SEED, shape=(N, 4))\n",
    "state = jrandom.normal(SEED, shape=(N, 4))\n",
    "omega = jrandom.normal(SEED, shape=(N, NUM_FEATURES, 2))\n",
    "phi = jrandom.uniform(SEED, minval=0, maxval=2 * jnp.pi, shape=(N, NUM_FEATURES,))\n",
    "\n",
    "predictions = foo(state, trans, omega, phi).mean(axis=(1,0))\n",
    "print(f\"Pred: {predictions}\")\n",
    "print(f\"True: {env.step(action)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR1: [ 2.3047597e-04  3.2374344e-05 -9.6576869e-06  4.8669985e-08\n",
      " -1.0052458e-05]\n",
      "RP1: [ 4.7717482e-08 -1.2887130e-08 -9.7361273e-08 -5.6822959e-08\n",
      "  2.2752496e-07]\n"
     ]
    }
   ],
   "source": [
    "theta = jnp.full((state_dim + 1,), .9)\n",
    "BETA = 1.\n",
    "ALPHA = 0.3\n",
    "N = 100\n",
    "HORIZON = 10\n",
    "NUM_FEATURES = 1000\n",
    "NOISE = 0.1\n",
    "lengthscales = jnp.full((NUM_FEATURES,), .1)\n",
    "coefs = jnp.full_like(lengthscales, 0.001)\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "trans_models = train_transition_models(replay_buffer, BETA, trans_models, NUM_FEATURES, lengthscales, coefs, SEED)\n",
    "\n",
    "keys = jrandom.split(SEED, num=4)\n",
    "state_epsilons = jrandom.normal(key=keys[0], shape=(N, HORIZON, 4))\n",
    "trans_epsilons = jrandom.normal(key=keys[1], shape=(100, HORIZON, 4))\n",
    "omegas = jrandom.normal(key=keys[2], shape=(N, HORIZON, NUM_FEATURES, 2))\n",
    "phis = jrandom.uniform(key=keys[3], minval=0, maxval=2 * jnp.pi, shape=(N, HORIZON, NUM_FEATURES))\n",
    "\n",
    "# LR gradients\n",
    "trajectories = get_trajectories(\n",
    "    theta, BETA, env, *trans_models, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons, trans_epsilons, omegas, phis\n",
    "    )\n",
    "lr_grads = lr_gradients(\n",
    "    theta, BETA, *trans_models, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, trajectories, trans_epsilons, omegas, phis\n",
    "    )\n",
    "print(f\"LR1: {lr_grads}\")\n",
    "\n",
    "# RP gradients\n",
    "rp_grads = policy_grad(\n",
    "    theta, BETA, *trans_models, env, HORIZON, NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons, trans_epsilons, omegas, phis\n",
    ")\n",
    "print(f\"RP1: {rp_grads}\")\n",
    "# rp_grads = trajectory_value(\n",
    "#     theta, BETA, jnp.zeros((4,)), *trans_models, jnp.arange(HORIZON - 1), NUM_FEATURES, lengthscales, coefs, NOISE, state_epsilons[0], trans_epsilons[0], omegas[0], phis[0]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle-based PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 50\n",
    "NOISE = 0.1\n",
    "HORIZON = 10\n",
    "TEST_HORIZON = 50\n",
    "N_STATES = 100\n",
    "N_TRANS = 100\n",
    "TRAIN_LOOPS = 5\n",
    "key = SEED\n",
    "\n",
    "\n",
    "theta = jnp.full((state_dim + 1,), 0.)\n",
    "params = jnp.array([theta])\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=0.005),\n",
    "    # optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for ep in range(MAX_EPISODES):\n",
    "    subkeys = jrandom.split(key, num=6)\n",
    "    key = subkeys[0]\n",
    "\n",
    "    state_epsilons = jrandom.normal(key=subkeys[1], shape=(N_STATES, HORIZON, 4))\n",
    "    trans_epsilons = jrandom.normal(key=subkeys[2], shape=(N_TRANS, HORIZON, 4))\n",
    "    omegas = jrandom.normal(key=subkeys[3], shape=(N_STATES, HORIZON, NUM_FEATURES, 2))\n",
    "    phis = jrandom.uniform(key=subkeys[4], minval=0, maxval=2 * jnp.pi, shape=(N_STATES, HORIZON, NUM_FEATURES))\n",
    "\n",
    "    # Train model with all available data\n",
    "    trans_models = train_transition_models(\n",
    "        replay_buffer, BETA, trans_models, NUM_FEATURES, lengthscales, coefs, subkeys[5]\n",
    "    )\n",
    "\n",
    "    for _ in range(TRAIN_LOOPS):\n",
    "        # Compute the policy gradient\n",
    "        # trajectories = get_trajectories(theta, BETA, env, *trans_models, HORIZON, NOISE, state_epsilons, trans_epsilons)\n",
    "        # grads = lr_gradients(theta, BETA, *trans_models, HORIZON, NOISE, trajectories, trans_epsilons)\n",
    "\n",
    "        # RP gradients\n",
    "        grads = policy_grad(\n",
    "            theta,\n",
    "            BETA,\n",
    "            *trans_models,\n",
    "            env,\n",
    "            HORIZON,\n",
    "            NUM_FEATURES,\n",
    "            lengthscales,\n",
    "            coefs,\n",
    "            NOISE,\n",
    "            state_epsilons,\n",
    "            trans_epsilons,\n",
    "            omegas,\n",
    "            phis\n",
    "        )\n",
    "\n",
    "        params = jnp.array([theta])\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        theta = params[0]\n",
    "\n",
    "    # Roll-out policy online for an episode and add to replay buffer\n",
    "    cur_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, theta)\n",
    "\n",
    "    if ep % 5 == 0:\n",
    "        print(f\"Ep {ep}, objective: {cur_obj}, theta: {theta}\")\n",
    "\n",
    "\n",
    "final_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, theta)\n",
    "print(f\"Final score: {final_obj}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect and organise training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = replay_buffer.get_train_test_arrays()\n",
    "\n",
    "train_X_d1 = train_X[:, :2]\n",
    "train_X_d2 = train_X[:, 2:4]\n",
    "train_X_d3 = train_X[:, 4:6]\n",
    "train_X_d4 = train_X[:, 6:8]\n",
    "test_X_d1 = test_X[:, :2]\n",
    "test_X_d2 = test_X[:, 2:4]\n",
    "test_X_d3 = test_X[:, 4:6]\n",
    "test_X_d4 = test_X[:, 6:8]\n",
    "\n",
    "train_y_d1 = train_y[:, 0]\n",
    "train_y_d2 = train_y[:, 1]\n",
    "train_y_d3 = train_y[:, 2]\n",
    "train_y_d4 = train_y[:, 3]\n",
    "test_y_d1 = test_y[:, 0]\n",
    "test_y_d2 = test_y[:, 1]\n",
    "test_y_d3 = test_y[:, 2]\n",
    "test_y_d4 = test_y[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2000\n",
    "\n",
    "omega = jrandom.normal(key=SEED, shape=(NUM_FEATURES, 2))\n",
    "phi = jrandom.uniform(key=SEED, minval=0, maxval=2 * jnp.pi, shape=(NUM_FEATURES, 1))\n",
    "lengthscales = jnp.full((NUM_FEATURES, 1), 1.)\n",
    "coefs = jnp.full_like(lengthscales, 1.)\n",
    "\n",
    "phi_X_train_d1 = phi_X(train_X_d1, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d1 = phi_X(test_X_d1, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d2 = phi_X(train_X_d2, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d2 = phi_X(test_X_d2, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d3 = phi_X(train_X_d3, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d3 = phi_X(test_X_d3, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_train_d4 = phi_X(train_X_d4, NUM_FEATURES, lengthscales, coefs, omega, phi)\n",
    "phi_X_test_d4 = phi_X(test_X_d4, NUM_FEATURES, lengthscales, coefs, omega, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RFF transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_d1 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d2 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d3 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "model_d4 = BLR(NUM_FEATURES, alpha=0.3, beta=1.)\n",
    "\n",
    "model_d1.posterior(phi_X_train_d1, train_y_d1)\n",
    "model_d2.posterior(phi_X_train_d2, train_y_d2)\n",
    "model_d3.posterior(phi_X_train_d3, train_y_d3)\n",
    "model_d4.posterior(phi_X_train_d4, train_y_d4)\n",
    "\n",
    "d1_preds = np.zeros_like(test_y_d1)\n",
    "d2_preds = np.zeros_like(test_y_d2)\n",
    "d3_preds = np.zeros_like(test_y_d3)\n",
    "d4_preds = np.zeros_like(test_y_d4)\n",
    "\n",
    "for i in range(test_y_d1.shape[0]):\n",
    "    d1_preds = model_d1.predict(phi_X_test_d1).mean()\n",
    "    d2_preds = model_d2.predict(phi_X_test_d2).mean()\n",
    "    d3_preds = model_d3.predict(phi_X_test_d3).mean()\n",
    "    d4_preds = model_d4.predict(phi_X_test_d4).mean()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE d1: {metrics.mean_absolute_error(test_y_d1, d1_preds)}\")\n",
    "print(f\"MSE d2: {metrics.mean_absolute_error(test_y_d2, d2_preds)}\")\n",
    "print(f\"MSE d3: {metrics.mean_absolute_error(test_y_d3, d3_preds)}\")\n",
    "print(f\"MSE d4: {metrics.mean_absolute_error(test_y_d4, d4_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Gaussian process transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gp_d1 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d2 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d3 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "gp_d4 = GaussianProcessRegressor(kernel=RBF(length_scale_bounds=(1e-4, 1e3)), n_restarts_optimizer=9)\n",
    "\n",
    "gp_d1.fit(train_X_d1, train_y_d1)\n",
    "gp_d2.fit(train_X_d2, train_y_d2)\n",
    "gp_d3.fit(train_X_d3, train_y_d3)\n",
    "gp_d4.fit(train_X_d4, train_y_d4)\n",
    "\n",
    "d1_preds_gp = np.zeros_like(test_y_d1)\n",
    "d2_preds_gp = np.zeros_like(test_y_d2)\n",
    "d3_preds_gp = np.zeros_like(test_y_d3)\n",
    "d4_preds_gp = np.zeros_like(test_y_d4)\n",
    "\n",
    "d1_std_gp = np.zeros_like(test_y_d1)\n",
    "d2_std_gp = np.zeros_like(test_y_d2)\n",
    "d3_std_gp = np.zeros_like(test_y_d3)\n",
    "d4_std_gp = np.zeros_like(test_y_d4)\n",
    "\n",
    "for i in range(test_y_d1.shape[0]):\n",
    "    d1_preds_gp, d1_std_gp = gp_d1.predict(test_X_d1, return_std=True)\n",
    "    d2_preds_gp, d2_std_gp = gp_d2.predict(test_X_d2, return_std=True)\n",
    "    d3_preds_gp, d3_std_gp = gp_d3.predict(test_X_d3, return_std=True)\n",
    "    d4_preds_gp, d4_std_gp = gp_d4.predict(test_X_d4, return_std=True)\n",
    "\n",
    "print(f\"MSE d1: {metrics.mean_absolute_error(test_y_d1, d1_preds_gp)}, kernel: {gp_d1.kernel_}\")\n",
    "print(f\"MSE d2: {metrics.mean_absolute_error(test_y_d2, d2_preds_gp)}, kernel: {gp_d2.kernel_}\")\n",
    "print(f\"MSE d3: {metrics.mean_absolute_error(test_y_d3, d3_preds_gp)}, kernel: {gp_d3.kernel_}\")\n",
    "print(f\"MSE d4: {metrics.mean_absolute_error(test_y_d4, d4_preds_gp)}, kernel: {gp_d4.kernel_}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d0f0160cacfb35fe8642b675725525dd1061e27bd6ae6db2781150554066f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
