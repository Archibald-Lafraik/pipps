{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import random\n",
    "import gym\n",
    "import jax.random as jrandom\n",
    "from jax import vmap, jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "from constants import SEED\n",
    "from policy import policy_grad, lr_gradients\n",
    "from utils import get_trajectories, rollout_episode\n",
    "from trans_model import prior, train_transition_models, lklhood_grad, marg_lklhood, trans_output\n",
    "from neural_nets import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('InvertedPendulum-v4')\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run random policy to collect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_EPISODES = 100\n",
    "BUFFER_CAPACITY = 1000\n",
    "HORIZON = 30\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity=BUFFER_CAPACITY)\n",
    "\n",
    "for ep in range(INIT_EPISODES):\n",
    "    cur_state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    for t in range(HORIZON):\n",
    "        action = np.array([random.uniform(-1., 1.)])\n",
    "        prev_state = cur_state\n",
    "\n",
    "        cur_state, _, done, _ = env.step(action)\n",
    "        replay_buffer.push(prev_state, action.squeeze(), cur_state)\n",
    "\n",
    "\n",
    "print(len(replay_buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute posterior distribution for transition models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = jnp.full((state_dim + 1,), .9)\n",
    "BETAS = jnp.full((4,), 20.)\n",
    "ALPHA = .3\n",
    "N = 1000\n",
    "NUM_FEATURES = 3\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models_pre = [model_d1, model_d2, model_d3, model_d4]\n",
    "trans_models_post = train_transition_models(\n",
    "    replay_buffer, BETAS, trans_models_pre, NUM_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Next State Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = jnp.array([.5])\n",
    "N = 1000\n",
    "NOISE = 0.05\n",
    "\n",
    "@jit\n",
    "def pred(start_st, state_eps, trans_eps, betas, model_noise, m_d1, m_d2, m_d3, m_d4):\n",
    "    model_input = jnp.stack([start_st, jnp.full((4,), action), jnp.ones((4,))]).T\n",
    "    L1 = jnp.linalg.cholesky(m_d1[1])\n",
    "    L2 = jnp.linalg.cholesky(m_d2[1])\n",
    "    L3 = jnp.linalg.cholesky(m_d3[1])\n",
    "    L4 = jnp.linalg.cholesky(m_d4[1])\n",
    "\n",
    "    w_d1 = m_d1[0] + L1 @ trans_eps[0]\n",
    "    w_d2 = m_d2[0] + L2 @ trans_eps[1]\n",
    "    w_d3 = m_d3[0] + L3 @ trans_eps[2]\n",
    "    w_d4 = m_d4[0] + L4 @ trans_eps[3]\n",
    "    \n",
    "    state_diff = trans_output(w_d1, w_d2, w_d3, w_d4, model_input)\n",
    "    next_mean = state_diff + start_st\n",
    "    next_state = next_mean + state_eps * model_noise \n",
    "    return next_state\n",
    "\n",
    "def state_prediction(start_state, state_epsilons, trans_epsilons, betas, model_noise, trans_models):\n",
    "    foo = vmap(pred, (None, 0, 0, None, None, None, None, None, None))\n",
    "    predictions = foo(\n",
    "        start_state, state_epsilons, trans_epsilons, betas, model_noise, *trans_models\n",
    "    )\n",
    "\n",
    "    return predictions\n",
    "\n",
    "keys = jrandom.split(SEED, num=4)\n",
    "state_eps = jrandom.normal(keys[0], shape=(N, 4))\n",
    "trans_eps = jrandom.normal(keys[1], shape=(N, 4, NUM_FEATURES))\n",
    "\n",
    "\n",
    "predictions_post = state_prediction(\n",
    "    jnp.zeros((4,)), state_eps, trans_eps, BETAS, NOISE, trans_models_post\n",
    "    ).mean(axis=0)\n",
    "print(f\"Pred: {predictions_post}\")\n",
    "print(f\"True: {env.step(action)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = replay_buffer.memory\n",
    "states = jnp.array(list(map(lambda t: t.state, transitions)))\n",
    "actions = jnp.array(list(map(lambda t: t.action, transitions)))\n",
    "next_states = jnp.array(list(map(lambda t: t.next_state, transitions)))\n",
    "\n",
    "N = 10000\n",
    "key = SEED\n",
    "keys = jrandom.split(key, num=4)\n",
    "num_states = len(transitions) \n",
    "pred_next_states = np.zeros((num_states, 4))\n",
    "\n",
    "for i, start_state in enumerate(states):\n",
    "    state_eps = jrandom.normal(keys[0], shape=(N, 4))\n",
    "    trans_eps = jrandom.normal(keys[1], shape=(N, 4, NUM_FEATURES))\n",
    "\n",
    "    pred_st = state_prediction(\n",
    "        start_state, state_eps, trans_eps, BETAS, NOISE, trans_models_post\n",
    "    ).mean(axis=0)\n",
    "    pred_next_states[i] = pred_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(states[:, 0], next_states[:, 0], color='orange', label=\"True transitions\")\n",
    "plt.scatter(states[:, 0], pred_next_states[:, 0], color='cornflowerblue', label=\"Predicted transitions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(SEED)\n",
    "BETAS = jnp.full((4,), 1.)\n",
    "ALPHA = 0.3\n",
    "N = 10000\n",
    "HORIZON = 10\n",
    "NOISE = 0.2\n",
    "NUM_FEATURES = 3\n",
    "\n",
    "model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "trans_models = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "trans_models_post = train_transition_models(replay_buffer, BETAS, trans_models, NUM_FEATURES)\n",
    "\n",
    "model_d1, model_d2, model_d3, model_d4 = trans_models_post\n",
    "\n",
    "key = SEED\n",
    "key, subkey = jrandom.split(key)\n",
    "subkeys = jrandom.split(subkey, num=2)\n",
    "state_epsilons = jrandom.normal(key=subkeys[0], shape=(N, HORIZON, 4))\n",
    "trans_epsilons = jrandom.normal(key=subkeys[1], shape=(N, HORIZON, 4, NUM_FEATURES))\n",
    "\n",
    "# LR gradients\n",
    "trajectories = get_trajectories(\n",
    "    params, BETAS, NOISE, env, *trans_models_post, HORIZON, state_epsilons, trans_epsilons\n",
    "    )\n",
    "lr_grads = lr_gradients(\n",
    "    params, BETAS, NOISE, *trans_models_post, HORIZON, trajectories, trans_epsilons,\n",
    "    )\n",
    "print(f\"LR: {lr_grads['mlp/~/linear_0']['w'][0, :6]}\")\n",
    "\n",
    "# RP gradients\n",
    "rp_grads = policy_grad(\n",
    "        params, BETAS, NOISE, *trans_models_post, env, HORIZON, state_epsilons, trans_epsilons,\n",
    "    )\n",
    "print(f\"RP: {rp_grads['mlp/~/linear_0']['w'][0, :6]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "lr_gradients_w0 = np.zeros((num_runs, 256 * 4))\n",
    "lr_gradients_b0 = np.zeros((num_runs, 256))\n",
    "rp_gradients_w0 = np.zeros((num_runs, 256 * 4))\n",
    "rp_gradients_b0 = np.zeros((num_runs, 256))\n",
    "lr_gradients_w1 = np.zeros((num_runs, 256))\n",
    "lr_gradients_b1 = np.zeros((num_runs, 256))\n",
    "rp_gradients_w1 = np.zeros((num_runs, 256))\n",
    "rp_gradients_b1 = np.zeros((num_runs, 256))\n",
    "\n",
    "key = SEED\n",
    "for k in range(num_runs):\n",
    "    key, subkey = jrandom.split(key)\n",
    "    subkeys = jrandom.split(subkey, num=2)\n",
    "    state_epsilons = jrandom.normal(key=subkeys[0], shape=(N, HORIZON, 4))\n",
    "    trans_epsilons = jrandom.normal(key=subkeys[1], shape=(N, HORIZON, 4, NUM_FEATURES))\n",
    "\n",
    "    # LR gradients\n",
    "    trajectories = get_trajectories(\n",
    "        params, BETAS, NOISE, env, *trans_models_post, HORIZON, state_epsilons, trans_epsilons\n",
    "        )\n",
    "    lr_grads = lr_gradients(\n",
    "        params, BETAS, NOISE, *trans_models_post, HORIZON, trajectories, trans_epsilons,\n",
    "        )\n",
    "    \n",
    "    lr_gradients_w0[k] = lr_grads['mlp/~/linear_0']['w'].reshape(-1) \n",
    "    lr_gradients_b0[k] = lr_grads['mlp/~/linear_0']['b']\n",
    "    lr_gradients_w1[k] = lr_grads['mlp/~/linear_1']['w'].reshape(-1) \n",
    "    lr_gradients_b1[k] = lr_grads['mlp/~/linear_1']['b']\n",
    "\n",
    "    rp_grads = policy_grad(\n",
    "        params, BETAS, NOISE, *trans_models_post, env, HORIZON, state_epsilons, trans_epsilons,\n",
    "    )\n",
    "    rp_gradients_w0[k] = rp_grads['mlp/~/linear_0']['w'].reshape(-1) \n",
    "    rp_gradients_b0[k] = rp_grads['mlp/~/linear_0']['b']\n",
    "    rp_gradients_w1[k] = rp_grads['mlp/~/linear_1']['w'].reshape(-1) \n",
    "    rp_gradients_b1[k] = rp_grads['mlp/~/linear_1']['b']\n",
    "\n",
    "\n",
    "print(f\"LR var layer 0 - weights: {lr_gradients_w0.var(axis=0).mean()}, bias: {lr_gradients_b0.var(axis=0).mean()}\")\n",
    "print(f\"RP var layer 0 - weights: {rp_gradients_w0.var(axis=0).mean()}, bias: {rp_gradients_b0.var(axis=0).mean()}\")\n",
    "print(f\"LR var layer 1 - weights: {lr_gradients_w1.var(axis=0).mean()}, bias: {lr_gradients_b1.var(axis=0).mean()}\")\n",
    "print(f\"RP var layer 1 - weights: {rp_gradients_w1.var(axis=0).mean()}, bias: {rp_gradients_b1.var(axis=0).mean()}\\n\")\n",
    "\n",
    "print(f\"RP mean variance: {np.mean([rp_gradients_w0.var(axis=0).mean(), rp_gradients_b0.var(axis=0).mean(), rp_gradients_w1.var(axis=0).mean(), rp_gradients_b1.var(axis=0).mean()])}\")\n",
    "print(f\"LR mean variance: {np.mean([lr_gradients_w0.var(axis=0).mean(), lr_gradients_b0.var(axis=0).mean(), lr_gradients_w1.var(axis=0).mean(), lr_gradients_b1.var(axis=0).mean()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle-based PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 200\n",
    "NOISE = 0.05\n",
    "HORIZON = 10\n",
    "TEST_HORIZON = 300\n",
    "N = 1000\n",
    "TRAIN_LOOPS = 10\n",
    "key = SEED\n",
    "\n",
    "trans_models = trans_models_post\n",
    "\n",
    "params = get_params(key)\n",
    "\n",
    "objectives = np.zeros((MAX_EPISODES,))\n",
    "\n",
    "schedule = optax.exponential_decay(\n",
    "    init_value=0.001,\n",
    "    transition_steps=100 * TRAIN_LOOPS,\n",
    "    decay_rate=0.9,\n",
    "    transition_begin=300,\n",
    "    staircase=False\n",
    ")\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=schedule),\n",
    "    # optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "subkeys = jrandom.split(key, num=6)\n",
    "for ep in range(MAX_EPISODES):\n",
    "    key = subkeys[0]\n",
    "\n",
    "    state_epsilons = jrandom.normal(key=subkeys[1], shape=(N, HORIZON, 4))\n",
    "    trans_epsilons = jrandom.normal(key=subkeys[2], shape=(N, HORIZON, 4, NUM_FEATURES))\n",
    "\n",
    "    model_d1 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "    model_d2 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "    model_d3 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "    model_d4 = prior(NUM_FEATURES, alpha=ALPHA)\n",
    "\n",
    "    trans_models = [model_d1, model_d2, model_d3, model_d4]\n",
    "\n",
    "    # Train model with all available data\n",
    "    trans_models = train_transition_models(replay_buffer, BETAS, trans_models, NUM_FEATURES)\n",
    "\n",
    "    for _ in range(TRAIN_LOOPS):\n",
    "        # Compute the policy gradient\n",
    "        # trajectories, trans_predictions = get_trajectories(\n",
    "        #     params, BETAS, env, *trans_models, HORIZON, NOISE, state_epsilons, trans_epsilons\n",
    "        #     )\n",
    "        # grads = lr_gradients(\n",
    "        #     params, BETAS, *trans_models, HORIZON, NOISE, trajectories, trans_predictions, trans_epsilons,\n",
    "        #     )\n",
    "\n",
    "        # RP gradients\n",
    "        grads = policy_grad(\n",
    "            params,\n",
    "            BETAS,\n",
    "            NOISE,\n",
    "            *trans_models,\n",
    "            env,\n",
    "            HORIZON,\n",
    "            state_epsilons,\n",
    "            trans_epsilons,\n",
    "        )\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Roll-out policy online for a few episode and add to replay buffer\n",
    "    cur_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, params)\n",
    "    objectives[ep] = cur_obj\n",
    "\n",
    "    if ep % 10 == 0:\n",
    "        # print(f\"Ep {ep}, objective: {cur_obj}, theta: {theta}\")\n",
    "        print(f\"Ep {ep}, objective: {cur_obj}\")\n",
    "\n",
    "final_obj = rollout_episode(env, TEST_HORIZON, replay_buffer, params)\n",
    "print(f\"Final score: {final_obj}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "366a8b492ecfaa4bf0d62f346fb918a62b31586cc3831a460e2f83d29276260d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
