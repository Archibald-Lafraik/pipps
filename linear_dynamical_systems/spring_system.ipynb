{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from spring_utils import get_observations, get_zs, get_A\n",
    "from spring_gradients import marginal_likelihood\n",
    "from training_spring import fit\n",
    "from constants import RAND_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = 0.1\n",
    "m = 3.\n",
    "k = 20.\n",
    "z = 0.5\n",
    "\n",
    "mu0 = jnp.array([3, 1])\n",
    "V0 = jnp.eye(2) * 0.0001\n",
    "trans_noise = jnp.eye(2) * 0.01\n",
    "obs_noise = jnp.eye(2) * 0.5\n",
    "\n",
    "\n",
    "JAX_KEY = jrandom.PRNGKey(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 500\n",
    "N = 4\n",
    "\n",
    "zs, xs = get_observations(k, delta_t, m, z, mu0, V0, trans_noise, obs_noise, num_steps, N, key=JAX_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(zs[:, 0, 0])\n",
    "plt.plot(xs[:, 0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the dynamics of the mass-spring system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "num_steps = 3\n",
    "NUM_TRAIN_STEPS = 1500\n",
    "\n",
    "_, xs = get_observations(k, delta_t, m, z, mu0, V0, trans_noise, obs_noise, num_steps, N)\n",
    "\n",
    "LR_ESTIMATOR = False\n",
    "\n",
    "A_init = jnp.eye(2)\n",
    "params = jnp.array([A_init])\n",
    "\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=0.0006),\n",
    "    optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "optimizer.init(params)\n",
    "\n",
    "print(f\"True value of A: {get_A(k, delta_t, m, z)}\\n\")\n",
    "\n",
    "learned_params, losses, gradients = fit(\n",
    "    params=params,\n",
    "    optimizer=optimizer, \n",
    "    training_steps=NUM_TRAIN_STEPS, \n",
    "    mu0=mu0, V0=V0,\n",
    "    trans_noise=trans_noise,\n",
    "    obs_noise=obs_noise, xs=xs, \n",
    "    num_steps=num_steps, \n",
    "    N=N, \n",
    "    lr_estimator=LR_ESTIMATOR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lr_training_objectives.npy', losses)\n",
    "epsilons = jrandom.normal(key=jrandom.PRNGKey(4), shape=(num_steps, N, 2))\n",
    "goal = marginal_likelihood(get_A(k, delta_t, m, z), mu0, V0, trans_noise, obs_noise, epsilons, xs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.axhline(goal, color='red', linestyle='dashed')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Variance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = 20\n",
    "NUM_TRAIN_STEPS = 1500\n",
    "num_samples = 10000\n",
    "\n",
    "all_rp_gradients = np.zeros((NUM_BATCHES, NUM_TRAIN_STEPS, 2, 2))\n",
    "all_lr_gradients = np.zeros((NUM_BATCHES, NUM_TRAIN_STEPS, 2, 2))\n",
    "\n",
    "key = RAND_KEY\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "    key, subkey = jrandom.split(key)\n",
    "    _, xs = get_observations(\n",
    "        k, delta_t, m, z, mu0, V0, trans_noise, obs_noise, num_steps, num_samples, key=subkey\n",
    "    )\n",
    "\n",
    "    # Reparameterized gradients\n",
    "    _, _, rp_gradients = fit(\n",
    "        params=params,\n",
    "        optimizer=optimizer, \n",
    "        training_steps=NUM_TRAIN_STEPS, \n",
    "        mu0=mu0, V0=V0,\n",
    "        trans_noise=trans_noise,\n",
    "        obs_noise=obs_noise, xs=xs, \n",
    "        num_steps=num_steps, \n",
    "        N=num_samples, \n",
    "        lr_estimator=False,\n",
    "        key=subkey\n",
    "    )\n",
    "\n",
    "    # Likelihood-ratio gradients\n",
    "    _, _, lr_gradients = fit(\n",
    "        params=params,\n",
    "        optimizer=optimizer, \n",
    "        training_steps=NUM_TRAIN_STEPS, \n",
    "        mu0=mu0, V0=V0,\n",
    "        trans_noise=trans_noise,\n",
    "        obs_noise=obs_noise, xs=xs, \n",
    "        num_steps=num_steps, \n",
    "        N=num_samples, \n",
    "        lr_estimator=True,\n",
    "        key=subkey\n",
    "    )\n",
    "\n",
    "    all_rp_gradients[i] = rp_gradients\n",
    "    all_lr_gradients[i] = lr_gradients\n",
    "\n",
    "np.save(f'rp_gradient_batches_{num_samples}_samples.npy', all_rp_gradients)\n",
    "np.save(f'lr_gradient_batches_{num_samples}_samples.npy', all_lr_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lr_gradients = all_lr_gradients.reshape(NUM_BATCHES, NUM_TRAIN_STEPS, -1)\n",
    "lr_grad_var = all_lr_gradients.var(axis=0)[:, 0].mean()\n",
    "print(lr_grad_var)\n",
    "\n",
    "all_rp_gradients = all_rp_gradients.reshape(NUM_BATCHES, NUM_TRAIN_STEPS, -1)\n",
    "rp_grad_var = all_rp_gradients.var(axis=0)[:, 0].mean()\n",
    "print(rp_grad_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = 1500\n",
    "samples = np.linspace(1e1, 1e6, 6, dtype=int)\n",
    "\n",
    "A_init = jnp.eye(2)\n",
    "params = jnp.array([A_init])\n",
    "\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=0.01),\n",
    "    optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "optimizer.init(params)\n",
    "\n",
    "A_diffs = np.zeros((samples.shape[0], NUM_TRAIN_STEPS, 4))\n",
    "\n",
    "for i, num_samples in enumerate(samples):\n",
    "    _, xs = get_observations(\n",
    "        k, delta_t, m, mu0, V0, trans_noise, obs_noise, num_steps, num_samples\n",
    "    )\n",
    "\n",
    "    # Reparameterized gradients\n",
    "    _, _, rp_gradients = fit(\n",
    "        params=params,\n",
    "        optimizer=optimizer, \n",
    "        training_steps=NUM_TRAIN_STEPS, \n",
    "        mu0=mu0, V0=V0,\n",
    "        trans_noise=trans_noise,\n",
    "        obs_noise=obs_noise, xs=xs, \n",
    "        num_steps=num_steps, \n",
    "        N=num_samples, \n",
    "        lr_estimator=False,\n",
    "    )\n",
    "\n",
    "    # Likelihood-ratio gradients\n",
    "    _, _, lr_gradients = fit(\n",
    "        params=params,\n",
    "        optimizer=optimizer, \n",
    "        training_steps=NUM_TRAIN_STEPS, \n",
    "        mu0=mu0, V0=V0,\n",
    "        trans_noise=trans_noise,\n",
    "        obs_noise=obs_noise, xs=xs, \n",
    "        num_steps=num_steps, \n",
    "        N=num_samples, \n",
    "        lr_estimator=True,\n",
    "    )\n",
    "\n",
    "    cur_diffs = np.abs(lr_gradients - rp_gradients).reshape(NUM_TRAIN_STEPS, -1)\n",
    "    A_diffs[i] = cur_diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caca = np.load(\"A_diffs.npy\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(samples, caca[:, :, 0].mean(axis=1), color=\"cornflowerblue\", label=\"A[0,0]\")\n",
    "plt.plot(samples, caca[:, :, 1].mean(axis=1), color=\"orange\", label=\"A[0,1]\")\n",
    "plt.plot(samples, caca[:, :, 2].mean(axis=1), color=\"green\", label=\"A[1,0]\")\n",
    "plt.plot(samples, caca[:, :, 3].mean(axis=1), color=\"purple\", label=\"A[1,1]\")\n",
    "plt.plot(samples, caca[:, :, :].mean(axis=(1,2)), color=\"pink\", label=\"Average\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d0f0160cacfb35fe8642b675725525dd1061e27bd6ae6db2781150554066f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
